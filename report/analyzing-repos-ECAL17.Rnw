\documentclass[letterpaper]{article}
\usepackage{natbib,alifeconf}
\usepackage{graphicx}        % standard LaTeX graphics tool
\usepackage{url} 
\usepackage[utf8]{inputenc}

\begin{document}


\title{Self-organized criticality in code repositories}

\author{J. J. Merelo$^{1}$, P. A. Castillo$^{1}$, Antonio M. Mora$^1$, Mario
  Garc\'ia-Valdez$^{2}$, Carlos Cotta${^3}$, Carlos Fernandes${^4}$ \\
\mbox{}\\
$^1$ Geneura Team, ETSIIT and CITIC, University of Granada (Spain),
{\tt \{jmerelo,pacv,amorag\}@ugr.es}\\
$^2$ Dept. of Graduate Studies, Instituto Tecnol\'ogico de Tijuana
(Mexico) {\tt mario@tectijuana.edu.mx}\\
$^3$ Dept. Lenguajes y Ciencias de la Computaci\'on, Universidad de M\'alaga (Spain), {\tt ccottap@lcc.uma.es}\\
$^4$ LASEEB, Lisbon (Portugal), {\tt cfernandes@laseeb.org}
}

%\SweaveOpts{concordance=TRUE}
% is it possible using relative-paths instead of absolute paths to set the file names?
<<setup, cache=FALSE,echo=FALSE,warning=FALSE,message=FALSE>>=
library(ggplot2)
library("ggfortify")
library(ggthemes)
library(dplyr)
library(TTR)
library(xtable)
                                        #use 
pref <- '../data/software/lines_'
files <- c('ejabberd_3-erl hrl yrl escript ex exs','tensorflow_2-py cc h',
           'mojo_2-pl pm PL','tty_2-rb','cask_5-el py','webpack_2-js','language-perl6fe_4-coffee p6',
           'tpot_5-py','scalatra_2-scala','Moose_2-pl pm xs t','django_8-py','docker_2-go',
           'fission_4-go py js','vue_2-js','Dancer2_2-pl pm t','rakudo_4-pm pm6 pl pl6 nqp')

urls <- c('processone/ejabberd','tensorflow/tensorflow',
          'kraih/mojo','piotrmurach/tty','cask/cask','webpack/webpack','perl6/atom-language-perl6',
          'rhiever/tpot','scalatra/scalatra','moose/Moose','django/django','docker/docker',
          'fission/fission','vuejs/vue','PerlDancer/Dancer2','rakudo/rakudo')

languages <- c('erlang','Python','Perl','Ruby','Emacs Lisp','JavaScript',
               'CoffeeScript','Python','Scala','Perl','Python','Go','Go','JavaScript','Perl','Perl')

age <-  data.frame(Name = character(),
                   file = character(),
                   language = character(),
                   age = integer(),
                   Median = double(),
                   Mean = double(),
                   SD = double())
url.list <- list()
for (i in 1:length(files) ) {
    file.name = paste0(pref,files[i],'.csv')
    these.lines <-  read.csv(file.name)
    url.list[[file.name]] <- urls[i]
    age <- rbind( age,
                 data.frame(Name = urls[i],
                            file = file.name,
                            language = languages[i],
                            age = length(these.lines$Lines.changed),
                            Median =  as.double(median(these.lines$Lines.changed)),
                            Mean = as.double(mean(these.lines$Lines.changed)),
                            SD = as.double(sd(these.lines$Lines.changed) )))
}
summary <- age[order(age$age),]
lines <- list()
# Read again in order because I am useless in R
for (i in 1:length(summary$file) ) {
    lines[[i]] <-  read.csv(as.character(summary[[i,'file']]))
    lines[[i]]$url <- url.list[[summary[[i,'file']]]]
    lines[[i]]$SMA10 <- SMA(lines[[i]]$Lines.changed,n=10)
    lines[[i]]$SMA20 <- SMA(lines[[i]]$Lines.changed,n=20)
}
@ 

\maketitle

\begin{abstract}
  Software development teams eventually become complex systems
reaching a critical state, a fact that has already been proved by
several researchers. This state, reached by self-organization, is
characterized by three conditions applied to the sequence of changes:
a scale-free structure, long-distance correlations, and so-called {\em
pink} noise. In this paper, we use a new methodology to measure
whether this self-organized critical (SOC) state actually
exists. Instead of focusing in a single and long-running project as is
usual, we will rather work on 16 different repositories with different
sizes and ages, and use a novel, more natural and precise methodology
to examine the sizes of changes. Our research shows that in all 16
repositories analyzed, at least one of the SOC characteristics exists,
and most of them exhibit all three, which leads us to think that SOC
is more widespread in software development than previously thought and
that very few initial conditions might be needed to reach it.
\end{abstract}

%\keywords{Complex systems, self-organizing systems, self-organized
%  criticality, power laws, artificial life}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   INTRODUCTION   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}\label{introduction}

Self-organized criticality (SOC) \citep{bak1988self} is a condition
that describes complex systems in many different venues and
environments. The dynamics of systems in this state is sometimes
compared to that of a sand pile \citep{paczuski1996avalanche}, in the
sense that 
the actual shape tends to reach also a critical state, 
represented in the sand pile by a
critical slope, and a single grain of sand creates avalanches
unrelated to the frequency of grains falling. This pile of sand is
also a simple model of a self-organized system that captures many of
its main characteristics, but its behavior is connected to the
experience of software developers and other people using work
coordination mechanisms to produce something measurable, that experience
certain periods of stasis followed by {\em avalanches} of work, new
code or new paragraphs without an apparent origin. 

The anecdotal evidence gathered by the authors confirms this kind of events
happens in software development teams, mainly in an open source context. 
% Antonio - Is this properly justified (as an 'anecdotal evidence')? I guess it happens due to the unorganized/unexpected contributions that can appear in open source projects, right?
% They are not unorganized, and we are not justifying anything, just
% giving a motivation why people would thing this is worthy of study - JJ
As a matter of fact, several researchers have
proved that many projects match the features of a critical state,
\citep{wu2007empirical,gorshenev2004punctuated,Merelo2016:repomining,gao2014analysis},
which is 
attributed to a stigmergy process \citep{robles05}. Stigmergy implies
collaboration without direct contact between agents, but through the
environment. In this case, collaborators interact through the code
itself and through messages left, like pheromones, in other
communication media, such as Slack, email or an IRC chat
application, task assignment systems or mailing lists. 
% un revisor se queja de esta frase justo anterior. Quizás la vea larga, pero sí tiene sentido  - Pedro
% Expandida y dividida. - JJ
These are probably just some of the self-organization processes taking place,
but the fact is that SOC predicts that the system will reach a
critical state through self-organization given very few initial
conditions. In this
critical state there are specific dynamic behaviors, like small
changes in the code base provoking {\em avalanches} of changes of all sizes and long-distance
correlations that make a particular change in a file cause
further changes down the line in a regular pattern. 

Furthermore, the case for this
critical state in software repositories is supported by several macro measures that certify the absence of a particular
scale in the size of changes, that is, a {\em scale-free} structure
\citep{wu2007empirical,gorshenev2004punctuated,Merelo2016:repomining}, but in some cases they also exhibit \emph{long-range correlations} and \emph{pink noise} \citep{szendro2001pink} in the power spectral density, with
noise or variations with respect to the normal frequency
changing in a way that is inversely proportional to it, higher frequency
changes getting a smaller spectral density
\citep{Merelo2016:repomining}.

Even if the existence of this SOC state in repositories is well
established, the choice of repositories to study is limited to
long-running and big projects such as the Linux kernel. However, in
fact SOC should need few initial conditions to take place. This is why
in this paper we will look at all kind of repositories, with {\em
  ages} starting at a few months and sizes, looking for the three
characteristics of systems in a critical self-organized
state. Besides,  we take a new approach to analyzing the repositories,
different from the usual one that considers daily changes in size for
the whole repository; instead, we introduce a {\em natural} timeline which uses as a {\em
  tick} the commit itself, and consider either increases or decreases in size, not only increases. 
% Antonio - as it is usual? as it was previously done?
% Don't understand what you mean - JJ
In fact, a refactorization where a number of lines is changed might
not show up in daily changes because size in lines might not change, 
while it will have an impact in this one equal to the number of lines changed. 

One of the intentions in this paper is to try and prove that, in the same
way it happens in neural systems \citep{10.3389/fnsys.2014.00166}, the
self-organized state might be essential to the software development
process, as long as it is done through an application that allows
collaboration, for instance, as a repository managed by a source code
control system such as {\tt git}. In fact, some explanations have been offered via conservation laws \citep{6784340} and other usual complex network
mechanisms such as preferential attachment \citep{lin2015power}.

% Antonio - It is not clear the motivation, rather than just 'observe' if SOC happens. Please, explain what will be the good news for developers or so if SOC is detected. ;)
% That is enough motivation. We don't know in advance if it happens or
% noT - jj
%% It reminds me about the cathedral vs bazaar discussion 
%% Add something about it if you want - JJ
% At any rate, software projects can be considered complex systems and
% as such we will study them in this paper. 

After some initial exploration of the subject and developing the
tools needed to mine repositories on GitHub \citep{merelo16:self}, in
this paper we will study many different software repositories, all of
them in active development, trying to find out 
the telltale signs of self-organized criticality, as enumerated above. 
Previously we have applied these techniques to different types of repositories
\citep{Merelo2016:repomining,merelo16:slash,merelo16:self}, finding
they  have
this scale-free size property.
% Antonio - Tell a bit about the findings in those previous papers... Something like "SOC was detected in all the cases". Therefore the motivation will be clearer in this one if that happened in previous works. ;)
% And this will make the paper well over the 9 pages I so painfully
% managed to reduce it - JJ

% In this paper, we are going  
% to work on a total of 16 repositories, chosen among those that have at
% least a few hundred commits, 
% % Antonio - Better say "more than a hundred commits" or so
% independently of the actual time it has taken to
% make them. Since repositories hold many kind of different files,
% including screen art, documentation and configuration files for building tools, we have focused on
% the code written in the two or three main languages of the repository
% itself, since in fact the dynamics of documentation and build tools is
% probably completely different; these languages have been found using
% the GitHub tool that reveals the percentage of code written in every
% language. 
% I will leave this for methodology- JJ

Our intention in this line of research is to eventually find when the
change of phase to the critical state occurs and if there are any
other signs related to it. That is why, in this paper, we will focus
on the characterization of software teams, as reflected in the work
logs, that are actually in that state. 

% I have deleted the LaTeX code to include the number of sections as this style does not support them   [pedro]
% Thanks - JJ
Next, after presenting a brief state of the art, we will explain our
methodology followed by the results obtained, closing with our
conclusions. 


% --------------------------------------------------------


\section{State of the art}\label{soa}

As far as we know, there has not been a continuing line of research on
self-organized criticality in software projects or, for that matter,
any other kind of collaborative work teams. The main reason might be
that researchers have thoroughly
proved that several big software repositories seem to be in a SOC state,
\citep{wu2007empirical,gorshenev2004punctuated}, although some
not-so-big and not-really-software repositories seem to be in that
state too \citep{Merelo2016:repomining,merelo16:slash,merelo16:self};
in these last papers suggest, that since these repositories have different characteristics in terms
of the number of users, age and type of information they hold implies that
self-organization, as it should be expected, is achieved with relative
ease and due to factors not related to the nature of the content being
developed, but the way the interaction is done itself. 

Indeed, this state of self-organized criticality
quantitatively proves what has been already established via
qualitative analysis, the fact that in many successful software
projects, developers self-organize \citep{Crowston2007564}, 
which is
the preferred way of working in distributed and volunteer
teams \citep{crowston2012free}. In fact, this way of organization
matches our own experience in development of open source projects such
as \citep{ae09,2016arXiv160101607M}, which are developed mainly by one
or a few coders, helped sporadically by other coders that find an
error and fix it or adapt the code to particular situations. 
In fact, this self-organization has also been observed in similar
projects such as Wikipedia \citep{10.1371/journal.pone.0017333}

A critical state might eventually emerge from self-organization
given the necessary conditions. However, there has been no work going further and
proving this even in the case that the team is carried out by a small team and
on repositories that are not devoted to software development. And this
critical state is key to carry the system to adaptive success, as
defined by \citet{benbya2006toward}, which presents 
the seven mechanisms that create complexity as initially enunciated for
biological systems and apply them to information system
development. 

One of these principles, the principle of {\em change rate}, which appears in the
way of observation-orientation-decision-action, is very explicit in
open source development, where you usually observe a repository or
project for a certain time, then find if there is something to fix or
the way you can adapt it to your particular circumstances, decide what
to do and how to do it, and, eventually, act on your fork, resulting in a
pull request to the original repository. These activities can
effectively be defined as social, so that teamwork in software
repositories is embedded in a kind of social
network. \citet{valverde2007self}
have proved how this network grows under the tension of top-down or
hierarchical rules and self-organization emerges from the bottom,
which makes software development teams a complex social system, indicating that the self-organized critical state would be much
more pervasive than initially thought. 

In this paper we will mine software repositories and take the measures
that would confirm they are in a self-organized critical
state. Eventually, our intention is to try and find the point when
phases change, although in this paper we will focus in studying the
existence of a self-organized criticality state in the repositories under study.
Next we
will present the methodology used to choose those repositories and
mine their information. 


% --------------------------------------------------------


\section{Methodology}
\label{sec:method}

We have chosen 16 repositories in different states of development, and representing from
web frameworks such as Django to Atom plugins in the case of {\em
  language-perl6e}. The projects they host are written in many different languages, either
interpreted or compiled, and vary also in {\em professionalism}, from
a recently started Atom editor plugin for Perl6 to Docker, an open
platform for building and running distributed applications,  
created and maintained by a fully professional community. 

Repository mining was done during the months of January to March
2017, although the particular time of collection should not have an
influence on the results, as long as they have a minimum amount of
commits. 

The way we look at changes in the repository is novel and was used for
the first time in the previous technical reports
\citep{Merelo2016:repomining}. When looking to find SOC in repositories
you have to look at the timeline of changes in those
repositories. In most papers so far, this timeline was {\em natural},
using days or weeks, and the change used was the increase in size
after every daily work. 

We will introduce several changes to this usual methodology. The first one
is the timeline: we will use a discrete timeline formed by the
commits, with every commit counting as time=1. 

The second one is that we will work with the size of changes to a particular
set of files in the repository, selected via wildcards; we exclude other 
artifacts such as images or style files. To extract information
about changes to these files in the repositories, we analyze the
repository log using a Perl script to extract the size of the changes
that have been made to the considered files. This discards many
commits from the initial set, leaving some repositories with less than
100 from the initial number. The actual number of commits modifying
code might vary from repository to repository; however this ratio is
not considered important as long as the remaining number of commits is
enough. 

The third methodological change introduced in this paper is referred
to code deltas. Since changes in commit logs include both the insertion and deletion of lines in
committed files, the largest of these values is taken; in particular,
this means that the addition of all changes will not be equal to the
sum of 
the sizes of all files. A change in two lines will appear in a diff 
as
``2 insertions, 2 deletions'', adding up to 0; that is why we consider
the largest of these two values; the main reason for doing so is also
that in fact, the algorithm that computes changes in the repository
examines similitude in lines and counts changes in two lines as two
insertions and two deletions. There is no way to find out whether
there have been actually two lines added somewhere and two deleted
somewhere else, so in absence of that, we opt for the heuristic of
using the largest of these two values as change size. This analysis
method is more precise that the one used by other authors, 
which takes
into account only changes in size in the whole repository, and thus does
not include activities such as refactoring that consist mainly in
making changes in place. It also has the granularity of single commits
and not days or weeks, which are not as problem-specific as using the
number of commits.

We extract this information via a Perl script, that generates a {\tt
  .csv} file with a single column with the sequence of changes in size in the files of interest in each
repository. These data files, as well as the repositories where they have
been measured, are available with a free license in the repository
that also hosts this paper\footnote{\url{http://github.com/JJ/literaturame}}. 

Please remember that the $x$ axis for these sequences of changes,
shown smoothed in Figure \ref{fig:smoothie}, does not correspond to physical time,
but simply to the commit number, and then only in changes of the
{\em interesting}, that is, code files. In this sense, there is an important difference between
our research methodology, which considers atomic changes, to papers such
as \citep{herraiz2009statistical}, which take into account {\em daily}
changes. We think that examining discrete changes does not impose a
particular rhythm, namely, daily, on the changes, but lets the
repository expose its own rhythm; it also allows us to examine
slow-changing repositories such as what is usual in non-critical open
source projects, that can be static for
a long time to experience a burst of changes all of a sudden;
precisely these changes can indicate an {\em avalanche} that is a
symptom of the underlying self-organized criticality state and might
be better detected using commits. An {\em avalanche} caused by a small change 
happening in a day followed by a flurry of changes will appear as a big change 
if the time unit is bigger than the discrete commit. 

Once the information from the repositories has been extracted, we
proceed to analyze it in the next section. 


% --------------------------------------------------------


\section{Results}
\label{res}
%
\begin{table*}[h!tb]
    \centering
<<commits, cache=FALSE,echo=FALSE>>=
kable.summary <- summary # Row names are useful
row.names(kable.summary) <- NULL
kable.summary$file <- NULL
kable( kable.summary,"latex",digits=2 )
@
\vspace*{1mm}
\caption{Summary of statistical measures for the software repositories
 we have analyzed here. {\tt Name} is the name of the repository in
 Github, {\tt age} is the total number of commits that affect the
 files under study, next is the main language the project uses, {\tt
   Mean} and {\tt Median} are computed over change sizes in number of
 lines, with {\tt SD} = standard deviation from the mean.\label{t:stat}}
\end{table*}
%
A summary of the statistical characteristics of the size of the commits,
in number of lines, is shown in Table \ref{t:stat}. From a macro point of view, median and
means are remarkably similar among themselves and with other
repositories that have been examined. Median changes are never bigger
than 100 lines and it can be as small as 6 or 9 lines. Means span
range bigger than the medians, from around 22 lines to several tens of thousands in the case of Tensorflow. The fact that the mean is so
separated from the median hints at a skewed
distribution. The book analyzed by \citet{merelo16:slash} had a median
of 10 lines, but a mean of 150 lines changed, in a distribution that
is different, much more skewed towards larger sizes, while the
software library analyzed by \citet{Merelo2016:repomining} had a median
of 9 and a mean of close to 32, which is remarkably similar to one of
the repositories analyzed here. This implies that the concept of {\em
  session}, or size of changes committed together, might be very
similar no matter what is the thing that is actually written. However, some repositories, specially ejabberd (a server written in Erlang for the Jabber protocol), Django and Tensorflow show the practice called {\em squashing}, which compresses several commits into a single one creating changes of several thousands lines. Those changes are not {\em organic} in the sense that they do not reflect the work of a single person. 
% Un revisor del GECCO pidió explicar esta frase - Pedro
In the big picture of the self-organization of the repository, its impact will have to be assessed, but in principle it would not have to have an influence on the overall state, since their scale will also follow the same principles. 

% in this figure, the different subplots should be identified (maybe including the name of repo in each case)  - Pedro
% It would take too much space. I'll just erase them all. Changed a
% bit, anyway - JJ
%\includegraphics{analyzing-paper_files/figure-latex/smoothie-1.pdf}
\begin{figure*}[h!tb]
  \centering
<<smoothie,message=FALSE,echo=FALSE,warning=FALSE,fig.height=7,fig.subcap=summary$Name,out.width='.115\\linewidth'>>=
for (i in 1:length(lines) ) {
    lines[[i]]$x = as.numeric(row.names(lines[[i]]))
    print(ggplot(lines[[i]]) +geom_line(aes(x=x,y=SMA10,color='SMA10'))+geom_line(aes(x=x,y=SMA20,color='SMA20'))+scale_y_log10()+ theme_tufte() + theme(legend.position="none",axis.title.x=element_blank(),axis.title.y=element_blank()))

}
@ 
\caption{Log of change size vs. commit number for all repositories, lines smoothed
  over 20 (blue) and 10 (red) changes. The order of the
  repositories is the same as in Table \ref{t:stat}. \label{fig:smoothie}}
\end{figure*}
% one of the GECCO reviewers said: "The text in figures 1, 2, 3, 4, and 5 is not readable".    -   pedro
% It is not needed, actually. The best is probably to suppress it - JJ
The timeline of the commit sizes is represented in a line chart in Figure \ref{fig:smoothie} with logarithmic \emph{y} scale and smoothing over several commits, either 10
or 20, depending on the color. The \emph{x} axis is simply the temporal
sequence of commits, while the \emph{y} axis is the absolute size of the
commit in number of lines. There are big changes in scale certain
\emph{rhythm} can be observed, which hints at large-scale
correlations, which has been created by current changes influencing other changes
that occur several, or many, steps in the future. 

Besides, these variations in scale might mean that commit sizes are distributed along a Pareto
distribution. We will examine this next, representing the number of changes of a particular
size in a log-log scale, with linear smoothing to show trends, in
Figure \ref{fig:changes}. 

% in this figure, the different subplots should be identified (maybe including the name of repo in each case)  - Pedro
%\includegraphics{analyzing-paper_files/figure-latex/linecount-1.pdf}
\begin{figure*}[h!tb]
  \centering
<<linecount,message=FALSE, fig.subcap=summary$Name, echo=FALSE,warning=FALSE,fig.height=4,out.width='.245\\linewidth'>>=
sizes.fit.df <- data.frame(Name = character(),
                           Coefficient = double(),
                           Intercept = double())
for (i in 1:length(lines) ) {
    by.lines <- group_by(lines[[i]],Lines.changed)
    lines.count <- summarize(by.lines, count=n())
    sizes.fit <- lm(log(1+lines.count$Lines.changed) ~ log(lines.count$count))
    repo <- strsplit(paste(summary[[1]][i],""),"_",fixed=T)
    sizes.fit.df <- rbind( sizes.fit.df,
                          data.frame( Name = repo[[1]][1],
                                     Intercept = summary(sizes.fit)$coefficients[1],
                                     Coefficient = summary(sizes.fit)$coefficients[2] ))
    print(ggplot(lines.count, aes(x=Lines.changed, y=count))+geom_point()+scale_x_log10()+scale_y_log10()+stat_smooth() + theme(legend.position="none",axis.title.x=element_blank(),axis.title.y=element_blank()) + ggtitle(lines[[i]]$url))
}
@ 
\caption{Number of changes of that size vs. lines changed in a log-log scale. The
  blue line and gray zone is a smoothed version of the chart. \label{fig:changes}}
\end{figure*}
%
This chart shows what seems to be a Pareto distribution, with the commit sizes
ranked in ascending order and plotted with a log-log scale. This distribution shows, in all cases, a {\em tail}
corresponding to big changes. This might be simply a consequence of
different practices by different authors, but also to different
in-company practices. It is specially remarkable the {\em fat tail} in
the case of Tensorflow and {\em ejabberd}, next-to-last row, first and
second from right. Due to some practices of merging a whole branch in
a single commit, a practice that is called {\em squashing}, they exhibit exceptionally big commit sizes, with
tens of thousands lines. In that case, that would show that there is
some top-down organization taking place, but it does not hide the
general self-organizing shape of the curve to their left.  

These distributions can, in fact, be linearly fit to a log-log distribution with coefficients
shown in Table \ref{t:sizes}. 
%
\begin{table}[h!]
    \centering
<<sizes, cache=FALSE,echo=FALSE>>=
kable( sizes.fit.df,"latex" )
@
\vspace*{2mm}
\caption{Summary of coefficients of the linear models adjusting number
  of change size occurrences vs. size.\label{t:sizes}}
\end{table}
%
These values are also similar to those found by
\citet{Merelo2016:repomining}, where the intercept was 6.02, above the
table, and the slope -0.001, a very mild slope that hints at a big
number of changes and might in fact indicate that, as would be
expected, the intercept increases and the slope decreases with the
number of changes or the size of the project. 
% The shape of the line in
% \citep{Merelo2016:repomining} in fact might be more similar to a {\em
%   broken stick}; this is a matter that deserves further
% investigation. 
In these repositories, the coefficient varies between negative
0.71 and 2.02 for Tensorflow. There does not seem to be a clear trend
with age, but this coefficient could depend on other factors
entirely. 

The scale free nature of the work in the repository can be more
properly observed by looking at the changes in some other way, ranking them by size
and representing them in a chart with a logarithmic \(y\) axis, in what is known as a {\em Zipf} chart. This is done in Figure \ref{fig:zipf}. 

% in this figure, the different subplots should be identified (maybe including the name of repo in each case)  - Pedro
% I didn't find the way to do it, but feel free to look it up - JJ
\begin{figure*}[h!tb]
  \centering
<<powerlaw,message=FALSE, fig.subcap=summary$Name,echo=FALSE,warning=FALSE,fig.height=4,out.width='.115\\linewidth'>>=
zipf.fit.df <- data.frame(Name = character(),
                          Coefficient = double(),
                          Intercept = double())
for (i in 1:length(lines) ) {
    sorted.lines <- data.frame(x=1:length(lines[[i]]$Lines.changed),Lines.changed=as.numeric(lines[[i]][order(-lines[[i]]$Lines.changed),]$Lines.changed))
    print(ggplot()+geom_point(data=sorted.lines,aes(x=x,y=Lines.changed))+scale_y_log10())
    sorted.lines.no0 <- sorted.lines[sorted.lines$Lines.changed>0,]
    repo <- strsplit(paste(summary[[1]][i],""),"_")
    zipf.fit <- lm(log(sorted.lines.no0$Lines.changed) ~ sorted.lines.no0$x)
    zipf.fit.df <- rbind( zipf.fit.df,
                         data.frame( Name = repo[[1]][1],
                                    Intercept = summary(zipf.fit)$coefficients[1],
                                    Coefficient = summary(zipf.fit)$coefficients[2] ))
}
@ 
\caption{Zipf, that is, ranked change sizes with logarithmic $y$ axis for the 16 repositories analyzed.\label{fig:zipf}}
\end{figure*}
%
%
We have fitted the logarithm of the change size to the rank of that
size, and shown the
Zipf exponents and intercepts for these models in Table
\ref{t:zipf}. These coefficients and are of the same order, but different range, that those
found by \citet{merelo16:slash}, where it hovers around 6 for the intercept and
-0.01 for the slope, indicating a similar state.
%
\begin{table}[h!tb]
    \centering
<<zipf, cache=FALSE,echo=FALSE>>=
kable( zipf.fit.df,"latex" )
@
\vspace*{2mm}
\caption{Summary of Zipf coefficients of the linear models.\label{t:zipf}}
\end{table}
%
The {\em evolution} in the nature of the distribution can be observed,
from a more or less straight line in the first cases, to something
more similar to a {\em broken stick} model in the last one, although it can
still be linearly fit to a log scale and there is a regime of size
changes that is still logarithmic in scale. Whatever the actual
distribution, there is no doubt that change sizes do not cluster
themselves along a central value and that there is scale-free nature
in them, which is, besides, independent of the {\em age} or total
number of changes of the paper, as it has been shown above. Unlike the
previous adjustment, there does seem to be a trend here towards a {\em
  flat} slope, changing from $10^{-2}$ for the {\em youngest}
repository to $10^{-4}$ for the oldest. A more gradual distribution
of sizes might be the cause, but it also indicates that, with age,
bigger {\em avalanches}, i.e. commits with many lines changed, occur due to the
self-organized critical state. 

Finally, these scale distributions hint at the possibility of
long-distance correlations, but in order to find this out, we will have
to plot the partial autocorrelation of the sequence, that is, the
relationship between the size of a change and the rest of the changes
in the sequence. This is computed and plotted in Figure
\ref{fig:auto}. 
%
% in this figure, the different subplots should be identified (maybe including the name of repo in each case)  - Pedro
%\includegraphics{analyzing-paper_files/figure-latex/autocorrelation-1.pdf}
% Again, don't know how to do it. It's the same order always. 
\begin{figure*}[h!tb]
  \centering
<<autocorrelation,message=FALSE, cache=FALSE,echo=FALSE,fig.height=4,fig.subcap=summary$Name,out.width='.115\\linewidth'>>=
for (i in 1:length(lines) ) {
    print(autoplot(pacf(lines[[i]]$Lines.changed, plot=FALSE) ))
}
@ 
\caption{Autocorrelation plot, dashed lines indicate statistical significance and line surpassing it indicating  self-correlation.\label{fig:auto}}
\end{figure*}
% 
Autocorrelation is significant only if the lines go over the mean
plotted as a dashed line. These long distance autocorrelations, already
found by \citet{Merelo2016:repomining}, are present here too. In the mentioned paper, there was positive
autocorrelation in the 21 commit period; in this case, it appears  in different places depending on the repository, but is present in most cases anyway.

In these repositories of increasing age, we find that actual long-distance autocorrelation only happens when they age, with no significant long-distance  autocorrelation in the first two repositories, and a significant one in most of the rest. However, while in the above mentioned work we found sharp peaks of long-distance correlation, in this case there are multiple peaks at many different distances, from short distance to very long distance of 30 and 40 commits. 

We will
focus on the third SOC feature, the presence of \emph{pink noise}, as measured by
the power spectral density, which we show in Figure
\ref{fig:spectrum}. The presence of {\em pink noise} would be
characterized by a spectrum with a log-log slope equal to $-1$, with
power decreasing inversely proportional to frequency.  
%
\begin{figure*}[h!tb]
  \centering
<<spectrum,message=FALSE, cache=FALSE,echo=FALSE,fig.height=4,fig.subcap=summary$Name,out.width='.245\\linewidth'>>=  
spec.fit.df <- data.frame(Name = character(),
                          Coefficient = double(),
                          p = double())
for (i in 1:length(lines) ) {
    this.spectrum <- spectrum(lines[[i]]$Lines.changed, plot=FALSE)
    print(autoplot( this.spectrum ) + scale_x_log10() + theme(legend.position="none",axis.title.x=element_blank(),axis.title.y=element_blank()) + ggtitle(lines[[i]]$url) )
    spec.fit <- lm(log(this.spectrum$spec) ~ log(this.spectrum$freq**2))
    repo <- strsplit(paste(summary[[1]][i],""),"_")
    f <- summary(spec.fit)$fstatistic
    p <- pf(f[1],f[2],f[3],lower.tail=F)
    attributes(p) <- NULL
    spec.fit.df <- rbind( spec.fit.df,
                         data.frame( Name = repo[[1]][1],
                                    p = p,
                                    Coefficient = summary(spec.fit)$coefficients[2] ))
}
@ 
\caption{Spectral density of changes, power vs. frequency.  \label{fig:spectrum}}
\end{figure*}
%
\begin{table}
    \centering
<<spec.tab, cache=FALSE,echo=FALSE>>=
kable( spec.fit.df,"latex" )
@
\vspace*{2mm}
\caption{Summary of coefficients of the linear models adjusting the
  power spectrum, and the p-value of the fit (values $>$ 0.05 indicate
 a bad fit).  Coefficients between 0 and -2 correspond to pink noise. \label{t:spec}}
\end{table}

In this case, we see that this {\em trend} appears with increasing
clarity from top left to bottom right. We performed a linear fit of
density to the square of the frequencies, with coefficients and p-values for the fit 
shown in Table \ref{t:spec}. Pink noise is characterized by
coefficient values between $0$ and $-2$, which is the case for all of
the repositories studied, with the only difference being the goodness
of the fit, which makes the hypothesis hold in all but 3 repositories:
{\tt language-perl6fe}, {\tt cask} and {\tt tty}. These are all
repositories with less than 1000 changes, although other 
repositories with similar number of commits do show this {\em pink
  noise} feature. 

Once the three main features of systems in a critical self-organized state have
been measured for all projects under study, our conclusions will be presented next. 


% --------------------------------------------------------


\section{Conclusions}\label{conc}


In this paper we were interested in finding traces of self-organized
criticality in software repositories by looking for certain features
that are peculiar to the critical state: scale-free behavior,
long-distance correlations and pink noise. Our methodology, which is
new in the sense that we have used counts size of commits as a
discrete measure, will show a much clearer picture of the state 
of the repository, since they correspond to units of work done and are
also related to discrete tasks in the ticketing system.

After analyzing the software repositories we can conclude that, in
fact, all repositories analyzed show some of the SOC features, specially
freedom of a particular scale in the size of the changes. However, we
could conclude from the measures taken above that there is a certain
amount of interaction, in the shape of commits, needed before the critical state is actually
reached. From the limited amount of repositories we have studied, we
could put this number between 100 and 1000 code-altering changes, with all
repositories examined over 1000 changes exhibiting self-organized
criticality. In particular, this would indicate that this critical
state emerges at an early project stage. On the other hand, there are some
differences depending on the software development methodology which
might impact the state of the repository, as has been seen in
the cases of repositories such as Tensorflow, which shows signs of
self-organization, but with measures and quantities in a whole
different range than the other repositories. 

In line with our open science policy, you can draw your own conclusions on your own repos by running the Perl
script hosted in \url{https://git.io/soc-repo}. This
repository holds also the data used in this study, as well as the
source for this paper, written using Knitr and including all the
scripts that process data and generate charts.

As a future line of work, we will first try to gather data from more
repositories, specially in the age boundary where we think
self-organization arises. Different types might show statistically significant
differences in the features of the critical state, which would be attributed rather 
than to the substrate itself to different types of collaboration. We
would also like to make more precise models of the ranked change
sizes, as well as the relation between number of changes and its
size. We will try to leverage repository measurements to develop
methodologies that improve collaboration and productivity. 


\section*{Acknowledgements}

This work has been supported in part by the Spanish Ministry of 
Econom\'{\i}a y Competitividad, project
TIN2014-56494-C4-\{1,3\}-P (\{UMA,UGR\}-EPHEMECH) and by CONACYT project 220590.

\bibliographystyle{apalike}
\bibliography{geneura,biblio}

\end{document}
