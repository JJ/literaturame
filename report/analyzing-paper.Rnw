\documentclass[]{llncs}
\usepackage{subcaption} % an alternative package for sub figures
\usepackage{llncsdoc}
\usepackage{lmodern}
%\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
  \newcommand{\euro}{€}
\fi
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\PassOptionsToPackage{usenames,dvipsnames}{color} % color is loaded by hyperref
\hypersetup{unicode=true,
            pdftitle={Self-organized criticality in repository-mediated projects},
            pdfauthor={J. J. Merelo},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}

\usepackage{framed}

\usepackage{graphicx,grffile}


\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
%\setcounter{secnumdepth}{0}

  \title{Finding self-organized criticality in collaborative work via repository mining}

  \author{J. J. Merelo\inst{1}, P. A. Castillo\inst{1}, Mario García-Valdez\inst{2}}
  \institute{Dept. of Computer Architecture, Geneura Team and CITIC,
    University of Granada (Spain)\\
    \email{\tt \{jmerelo,pacv\}@ugr.es}
\and
  Mario add yours}

\begin{document}
%\SweaveOpts{concordance=TRUE}
% is it possible using relative-paths instead of absolute paths to set the file names?
<<setup, cache=FALSE,echo=FALSE>>=
library(ggplot2)
library("ggfortify")
library(dplyr)
library(TTR)
#use 
files <- c('../data/papers/lines_2016-DCAI_ALL_ALL_tex.csv','../data/papers/lines_2016-ea-languages-PPSN_ea-languages_Rnw.csv','../data/papers/lines_2015_books_ALL_tex.csv','../data/papers/lines_modeling-volunteer-computing_ALL_ALL_tex.csv')
lines <- list()
summary <- data.frame(Name = character(),
                      Mean = double(),
                      Median = double(),
                      SD = double())
for (i in 1:length(files) ) {
# for testing here
    lines[[i]] <- read.csv(files[i]) # File should be established from an R script
    summary <- rbind( summary,
                     data.frame( Name= gsub(".+lines_(.+)_\\w+\\..+","\\1",files[i]),
                                Mean = as.double(mean(lines[[i]]$Lines.changed)),
                                Median = as.double(median(lines[[i]]$Lines.changed)), 
                                SD = as.double(sd(lines[[i]]$Lines.changed) ) ) )
    lines[[i]]$SMA5 <- SMA(lines[[i]]$Lines.changed,n=5)
    lines[[i]]$SMA10 <- SMA(lines[[i]]$Lines.changed,n=10)
    lines[[i]]$SMA20 <- SMA(lines[[i]]$Lines.changed,n=20)

}
@ 
\maketitle

\begin{abstract}
  In order to improve team productivity, it is interesting to find 
  % Maybe it is the whole software development process (Quality, Less Stress, User Commitment, etc.)
  % Don't know what you mean.
  out the dynamics underlying collaboration  and their
  mechanisms. These mechanisms might not be explicit or organized from
  the top, but arise from
  the collaboration and the way it is done and rather be
  self-organizing. This is why finding if self-organization takes place and under which
  conditions will yield some insights on this process, and, from this,
  we can deduce some hints on
  how to improve it. In this paper we will focus on the former,
  examining repositories where the collaborative writing of scientific
  papers by our research team is taking place show hints of a critical
  state, which can be measured by the 
existence of a scale-free structure, long-distance correlations and
{\em pink}
noise when analyzing the size of changes and its time series. This
critical state is reached via self-organization, which is why it is
called self-organized criticality. Our
intention is to prove that, although with different characteristics,
most repositories independently of the number of collaborators and its real
nature, self-organizes, which implies that it is the nature of the
interactions, and not the object of the interaction, which takes the
project to a critical state. This critical state has already been
established in a number of repositories with different types of
projects, such as software or even literary works; we will also find
if there is any essential difference between the macro measures of the
states reached by these and the object of this paper. 
\end{abstract}

\section{Introduction}\label{introduction}

The existence of a self-organized critical state \cite{bak1988self} in
software repositories has been well established \cite{wu2007empirical,gorshenev2004punctuated,Merelo2016:repomining,gao2014analysis} and
attributed to an stigmergy process \cite{robles05} in which collaborators interact through the code
itself and other communication media, such as the Slack or IRC chat
application, task assignment systems or mailing lists. The case for this
critical state is supported  mainly by the non-existence of a particular
scale in the size of changes
\cite{wu2007empirical,gorshenev2004punctuated}, but in some cases they
also exhibit long-range 
correlations and a \emph{pink noise} in the power spectral density, with
\emph{noise} or variations with respect to the \emph{normal} frequency
changing in a way that is inversely proportional to it, higher frequency
changes getting a smaller spectral density. This state favors
evolvability of the underlying software system \cite{1544757}, as
oposed from the the lack of this quality in software created by a
top-down organization process. That is why this quality has been
mainly studied in open source software systems which follow a more
open model of development; however, it might happen that, in the same
way it happens in neural systems \cite{10.3389/fnsys.2014.00166}, the
self-organized state might be essential to the software development
process, as long as it is done in an application that allows
collaboration such as a repository managed by a source control system
such as git. In fact, some explanations have been offered via
conservation laws \cite{6784340} and other usual complex network
mechanisms such as preferential attachment \cite{lin2015power}· 
%% It remind me about the cathedral vs bazaar discussion 
%%

After examining and establishing the existence of this state in the
software repository for the Moose library, in this report we are going  % maybe a reference or footnote to this repo (https://github.com/moose) should be added?  - Pedro
to work on a repository for a paper our research group has been working
for a long time. Since our research group supports open science, we
develop in open software repositories, and this one can be found in
\url{https://github.com/geneura-papers/2015_books} . This particular
paper has been chosen since it has been a work in progress for more than
one a year, and in fact in this precise moment it is in the process of  % finally, it was accepted and published.
being reviewed to be submitted again to a journal. \emph{Developing} a
paper using a repository is a good practice that allows easy
distribution of tasks, attribution, and, combined with the use of
\emph{literate} programming tools that allow the embedding of code
within the text itself, providing a closer relationship between data and report
and, of course, easier reproducibility.


Coming up next, we will examine the methodology followed to extract
information from the repository and how we have processed it. 
After presenting a brief \protect\hyperlink{soa}{state of the art} next, 
followed by the \protect\hyperlink{methodology}{methodology},
obtained \protect\hyperlink{res}{results} will be presented % in the next section, 
and eventually we will expose our \protect\hyperlink{conc}{conclusions}. 

\hypertarget{soa}{\section{State of the art}\label{soa}}

As far as we know, there has not been a continuing line of research on
self-organized criticality in teamwork. Researchers have throughly
proved that software repositories seem to be in a SOC state,
\cite{wu2007empirical,gorshenev2004punctuated}, including our own
reports \cite{Merelo2016:repomining,merelo16:slash,merelo16:self}
where we examine and establish the existence of repositores in a
critical state to which they have arrived via self-organization; the
fact that these repositories have different characteristics in terms
of the number of users, age and type of information they hold implies that
self-organization, as should be expected, is achieved with relative
ease. In fact, this state of self-organized criticality
quantitatively proves what has been already established via
qualitative analysis, the fact that in many successful software
projects, developers self-organize \cite{Crowston2007564}, which is
the preferred way of working in distributed and volunteer
teams.% Reference 
Self-organized criticality arise from
self-organization. However, there has been no work going further and
proving this even in the case that work is done by a few persons and
on repositories that are not devoted to software development.


In this paper we will examine different repositories with the same purpose,
all devoted to the collaborative writing of scientific papers, but
each with a different age, in order to try and find out if self-organization
arrives simply with age and, if so, what seems to be this critical
age. 


\hypertarget{methodology}{\section{Methodology}\label{methodology}}

To extract information of changes in this file, changes have been %which file?
circumscribed to the paper itself: two files including the paper and
the response to reviewers, which are the ones that are more particularly related
to the project. Other files are considered artifacts (for instance,
images) and are not taken into account. The repository is analyzed with
a Perl script and a sequence of lines changed in each commit is
generated. Since changes include both the insertion and deletion of lines within
those files, the biggest of these values is taken; in particular, this
means that the addition of all changes will not be equal to the sum of
the sizes of all files. A change in two lines will appear in a diff as
``2 insertions, 2 deletions'', adding up to 0; that is why we consider
the bigger of these two values.


\hypertarget{res}{\section{Results}\label{res}}

A summary of the statistical characteristics of the size of the commits,
in number of lines, is shown in Table \ref{t:stat}.
%
\begin{table}
    \centering
<<commits, cache=FALSE,echo=FALSE>>=
kable( summary,"latex" )
@
\caption{Summary of statistical measures for the four papers we have
  been analyzing here.\label{t:stat}}
\end{table}
%
This table shows that, at least from a macro point of view, median and
averages are remarkably similar, with the median between 9 and 22 lines
and the average between 24 and 54. The fact that the average is so
separated from the median is already a hint that this is a skewed
distribution. 

The timeline of the commit sizes is represented next with logarithmic or
decimal \emph{y} scale. The serrated characteristic is the same, as well
as the big changes in scale. The \emph{x} axis is simply the temporal
sequence of commits, while the \emph{y} axis is the absolute size of the
commit in number of lines.

% \includegraphics{analyzing-paper_files/figure-latex/timeline-1.pdf}
% \includegraphics{analyzing-paper_files/figure-latex/timeline-2.pdf}
\begin{figure*}[h!tb]
  \centering
<<timeline, cache=FALSE,echo=FALSE,fig.height=7,fig.subcap=c('DCAI','PPSN','Book Prediction','Volunteer computing'),out.width='.48\\linewidth'>>=
for (i in 1:length(lines) ) {
    lines[[i]]$x = as.numeric(row.names(lines[[i]]))
    print(ggplot(lines[[i]]) + geom_point(aes(x=x,y=Lines.changed,group=1))+scale_y_log10())
}
@
\caption{Lines changed per commit in a log-y scale.\label{fig:tl}}
\end{figure*}

A certain \emph{rhythm} can be observed. Probably it will be a bit more
visible if we do an order 10 and then an order 20 smoothing, averaging
over that number of changes.
%
%\includegraphics{analyzing-paper_files/figure-latex/smoothie-1.pdf}
\begin{figure*}[h!tb]
  \centering
<<smoothie,message=FALSE, cache=FALSE,echo=FALSE,warning=FALSE,fig.height=7,fig.subcap=c('DCAI','PPSN','Book Prediction','Volunteer computing'),out.width='.48\\linewidth'>>=
for (i in 1:length(lines) ) {
     print(ggplot(lines[[i]]) +geom_line(aes(x=x,y=SMA10,color='SMA10'))+geom_line(aes(x=x,y=SMA20,color='SMA20'))+scale_y_log10())
}
@ 
\caption{Smoothed line over 20 and 10 changes, shown in different colors.\label{fig:smoothie}}
\end{figure*}

The change in scale might mean that it is distributed using a Pareto
distribution. Next we represent the number of changes of a particular
size in a log-log scale, with linear smoothing to show the trend.

%\includegraphics{analyzing-paper_files/figure-latex/linecount-1.pdf}
\begin{figure*}[h!tb]
  \centering
<<linecount,message=FALSE, cache=FALSE,echo=FALSE,warning=FALSE,fig.height=8,fig.subcap=c('DCAI','PPSN','Book Prediction','Volunteer computing'),out.width='.48\\linewidth'>>=
sizes.fit.df <- data.frame(Name = character(),
                        Coefficient = double(),
                        Intercept = double())
for (i in 1:length(lines) ) {
    by.lines <- group_by(lines[[i]],Lines.changed)
    lines.count <- summarize(by.lines, count=n())
    sizes.fit <- lm(log(1+lines.count$Lines.changed) ~ log(lines.count$count))
    sizes.fit.df <- rbind( sizes.fit.df,
                          data.frame( Name = summary[[1]][i],
                                     Coefficient = summary(sizes.fit)$coefficients[1],
                                     Intercept = summary(sizes.fit)$coefficients[2] ))
    print(ggplot(lines.count, aes(x=Lines.changed, y=count))+geom_point()+scale_x_log10()+scale_y_log10()+stat_smooth())
}
@ 
\caption{Number of changes vs size in a log-log scale.\label{fig:changes}}
\end{figure*}
%
This distribution appears as a Zipf distribution, with the commit sizes
ranked in descending order and plotted with a logarithmic \emph{y} axis.
I can be linearly fit to a log-log distribution with coefficients
4.7287153, -1.0782681, which we can compare with the results in
\cite{Merelo2016:repomining}, with a slope coefficient equal to
\texttt{-0.9608}. The coefficients for all repositories are shown in
Table \ref{t:sizes}
%
\begin{table}
    \centering
<<sizes, cache=FALSE,echo=FALSE>>=
kable( sizes.fit.df,"latex" )
@
\caption{Summary of coefficients of the linear models adjusting the
  number of lines and size.\label{t:sizes}}
\end{table}
%
We can look at the changes in some other way, ranking changes by size
and representing them in a graph with a logarithmic \(y\) axis, as well as
in the form of an histogram.

\begin{figure*}[h!tb]
  \centering
<<powerlaw,message=FALSE, cache=FALSE,echo=FALSE,warning=FALSE,fig.height=8,fig.subcap=c('DCAI','PPSN','Book Prediction','Volunteer computing'),out.width='.245\\linewidth'>>=
zipf.fit.df <- data.frame(Name = character(),
                        Coefficient = double(),
                        Intercept = double())
for (i in 1:length(lines) ) {
    print(ggplot(data=lines[[i]], aes(lines[[i]]$Lines.changed)) + geom_histogram(bins=100)+scale_x_log10())
    sorted.lines <- data.frame(x=1:length(lines[[i]]$Lines.changed),Lines.changed=as.numeric(lines[[i]][order(-lines[[i]]$Lines.changed),]$Lines.changed))
    print(ggplot()+geom_point(data=sorted.lines,aes(x=x,y=Lines.changed))+scale_y_log10())
    sorted.lines.no0 <- sorted.lines[sorted.lines$Lines.changed>0,]
    zipf.fit <- lm(log(sorted.lines.no0$Lines.changed) ~ sorted.lines.no0$x)
    zipf.fit.df <- rbind( zipf.fit.df,
                         data.frame( Name = summary[[1]][i],
                                    Coefficient = summary(zipf.fit)$coefficients[1],
                                    Intercept = summary(zipf.fit)$coefficients[2] ))
}
@ 
\caption{Changes, ordered by size, and represented in a logarithmic
  $y$ axis.\label{fig:zipf}}
\end{figure*}
%
%
The Zipf exponent for these models are shown in Table \ref{t:zipf}, which is also
in the same range as the one found in \cite{Merelo2016:repomining}.
%
\begin{table}
    \centering
<<zipf, cache=FALSE,echo=FALSE>>=
kable( zipf.fit.df,"latex" )
@
\caption{Summary of Zipf coefficients of the linear models adjusting the
  number of lines and size.\label{t:zipf}}
\end{table}
%

Finally, these scale distributions hints at the possibility of
long-scale correlations. The partial autocorrelation is plotted in the
next figure. %ref needed

%\includegraphics{analyzing-paper_files/figure-latex/autocorrelation-1.pdf}
\begin{figure*}[h!tb]
  \centering
<<autocorrelation,message=FALSE, cache=FALSE,echo=FALSE,fig.height=8,fig.subcap=c('DCAI','PPSN','Book Prediction','Volunteer computing'),out.width='.48\\linewidth'>>=
for (i in 1:length(lines) ) {
    print(autoplot(pacf(lines[[i]]$Lines.changed, plot=FALSE) ))
}
@ 
\caption{Autocorrelation plot. \label{fig:auto}}
\end{figure*}
% 
The spikes around the 20 commit mark, which also appeared in 
% maybe use 20th commit ? or then commit number 20 or maybe commit 20 
 \cite{Merelo2016:repomining}, are present here. In that case, there was positive
autocorrelation in the 21 commit period; in this case, it appears at 25
and 15. It shows, anyway, that the size of a commit has a clear
influence further down writing history, with high autocorrelations
around 20 commits.

With two of the three features of the critical state present, we will
focus on the third, the presence of \emph{pink} noise, as measured by
the power spectral density, shown below

%\includegraphics{analyzing-paper_files/figure-latex/spectrum-1.pdf}
\begin{figure*}[h!tb]
  \centering
<<spectrum,message=FALSE, cache=FALSE,echo=FALSE,fig.height=8,fig.subcap=c('DCAI','PPSN','Book Prediction','Volunteer computing'),out.width='.48\\linewidth'>>=  
for (i in 1:length(lines) ) {
    print(autoplot(spectrum(lines[[i]]$Lines.changed, plot=FALSE) ))
}
@ 
\caption{Spectral density of changes. \label{fig:spectrum}}
\end{figure*}
%
The fact that there is not a clear trend downwards that would indicate
the \texttt{1/frequency} state of the power spectrum indicates that, in
this case, this feature does not show up. It might be the case that \emph{pink}
noise appears later on in development, or simply needs larger periods to
appear. The fact that this third characteristic of the self-organized
state is not present does not obscure the other two, however, which
appear clearly and significantly.


\hypertarget{conc}{\section{Conclusions}\label{conc}}

After analyzing the software repository for a scientific paper, we can
% is not just the repository? is not software yet
conclude that it is in a critical state, as proved by the fact that its
changes have a scale-free form and that there are long-distance
correlations, with \emph{long} indicating here a distance further than
the two or three closer commits. Differently from other papers, we have
used commits as a discrete measure, not \emph{dailies} or other time
measure, since development often stops for several days more clearly in
the case of this paper, where nothing was done for months, and nothing
between submission and the first revision. We think that commits, and
not actual time measures, will show a much clearer picture of the state
of the repository, since they correspond to units of work done and are
also related to discrete tasks in the ticketing system.

% Comment: There is other information that could be exploited that
% IMO is more related with self-organization, and is the author of
% the commit. Maybe rules of interaction arise when for instance some one takes the lead
% and others wait for him to work, and then make little corrections.

You can draw your own conclusions on your own repos by running the Perl
script in \url{http://github.com/JJ/literaturame}. As future line of
work, we will compare different paper repositories, and these with other
type of repositories, and see if there are some outstanding and
statistically significant differences, which would be attributed rather
than the substrate itself, to different types of collaboration.


\section*{Acknowledgements}
This work has been supported in part by:
 Ministerio de Ministerio espa\~{n}ol de Econom\'{\i}a y Competitividad under project TIN2014-56494-C4-3-P (UGR-EPHEMECH)

\bibliographystyle{splncs03}
\bibliography{geneura,biblio}

\end{document}
