\documentclass{sig-alternate}
\usepackage{graphicx}        % standard LaTeX graphics tool
\usepackage{url} 
\usepackage{listings}
\usepackage{color}
\usepackage{color}
\usepackage{alltt}
\usepackage[T1]{fontenc}
\lstset{
basicstyle=\ttfamily \scriptsize,
language=java,
frame=single,
stringstyle=\ttfamily,
showstringspaces=false
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{subcaption} % an alternative package for sub figures
\usepackage{llncsdoc}
\usepackage{lmodern}
%\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

%\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\PassOptionsToPackage{usenames,dvipsnames}{color} % color is loaded by hyperref
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}

\usepackage{framed}

\usepackage{graphicx,grffile}

\setlength{\abovecaptionskip}{20pt plus 3pt minus 2pt}

\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
%\setcounter{secnumdepth}{0}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\providecommand{\e}[1]{\ensuremath{\times 10^{#1}}}
\begin{document}
%
% --- Author Metadata here ---
\conferenceinfo{GECCO'16,} {July 2017.} 
\CopyrightYear{2016} 
\crdata{xxx-x-xxxx-xxxx-x/xx/xx} 
\clubpenalty=10000 
\widowpenalty = 10000

\title{Self-organized criticality in code repositories}

\numberofauthors{1}
\author{
 \alignauthor
        No Author\\
        \affaddr{University}\\
        \affaddr{Department}\\
        \affaddr{City, Country}\\
        \email{me@email.com}
}

%   \author{J. J. Merelo\inst{1}, P. A. Castillo\inst{1}, Mario Garc√≠a-Valdez\inst{2}}
%   \institute{Geneura Team, ETSIIT and CITIC, University of Granada (Spain)\\
%     \email{\tt \{jmerelo,pacv\}@ugr.es}
% \and
%   Dept. of Graduate Studies, Instituto Tecnologico de Tijuana (Mexico)\\
%     \email{\tt mario@tectijuana.edu.mx}
% }


%\SweaveOpts{concordance=TRUE}
% is it possible using relative-paths instead of absolute paths to set the file names?
<<setup, cache=FALSE,echo=FALSE,warning=FALSE,messages=FALSE>>=
library(ggplot2)
library("ggfortify")
library(dplyr)
library(TTR)
#use 
pref <- '../data/software/lines_'
files <- c('ejabberd_3-erl hrl yrl escript ex exs','tensorflow_2-py cc h',
           'mojo_2-pl pm PL','tty_2-rb','cask_5-el py','webpack_2-js','language-perl6fe_4-coffee p6',
           'tpot_5-py','scalatra_2-scala','Moose_2-pl pm xs t','django_8-py','docker_2-go',
           'fission_4-go py js','vue_2-js','Dancer2_2-pl pm t','rakudo_4-pm pm6 pl pl6 nqp')
age <-  data.frame(Name = character(),
                   age = integer())
for (i in 1:length(files) ) {
    this.file <-  read.csv(paste0(pref,files[i],'.csv'))
    age <- rbind( age,
                 data.frame( Name = files[i],
                            age = length(this.file$Lines.changed)))
}
files <- age[order(age$age),]$Name
lines <- list()
summary <- data.frame(Name = character(),
                      Mean = double(),
                      Median = double(),
                      SD = double(),
                      age = integer())

for (i in 1:length(files) ) {
# for testing here
    file.name <- paste0(pref,files[i],'.csv')
    lines[[i]] <- read.csv(file.name) # File should be established from an R script
    summary <- rbind( summary,
                     data.frame( Name= files[i],
                                Mean = as.double(mean(lines[[i]]$Lines.changed)),
                                Median = as.double(median(lines[[i]]$Lines.changed)), 
                                SD = as.double(sd(lines[[i]]$Lines.changed) ),
                                age = length( lines[[i]]$Lines.changed ) ) )
    lines[[i]]$SMA10 <- SMA(lines[[i]]$Lines.changed,n=10)
    lines[[i]]$SMA20 <- SMA(lines[[i]]$Lines.changed,n=20)

}
@ 
\maketitle

\begin{abstract}
  Finding the fitness of complex systems such as software development
  team is a difficult task without straightforward
  solutions. 
  In order to improve team productivity and interactions  within the team
  as well as the willingness of occasional volunteers, it is
  interesting to find   
  out the mechanism underlying collaboration in open
  source projects and their dynamics. These mechanisms might not be
  explicit or organized in a top-down fashion, but arise from
  the collaboration and the way it is done, being thus
  self-organizing. This is why finding if open source code
  repositories are in a particular, critical, state, reached via self-organization, and what are the conditions
  to reach that state will yield some insights on this process, and, from this,
  we can deduce some rules on how to interactions and thus productivity. % How to improve? interactions - Mario
% Antonio - no queda claro a quÈ se refiere 'it' (state, productivity)
  % Aclarado - JJ
 In this paper we will focus on trying to find this self-organized
 criticality which makes the project a complex system and implies
 certain rules on its future evolution, state by examining repositories, hosted in GitHub, for open source projects,
  and taking a series of measures to see if they show the characteristics of a critical state, 
% Antonio - aclarar quÈ es el 'critical state'
  % explicado arriba - JJ
which can be deduced by the 
existence of a scale-free structure, long-distance correlations and so-called
{\em pink} noise 
% Antonio - Aclarar quÈ es esto del 'ruido rosa'
% AÒadido so-called, se aclarar· luego - JJ
when analyzing the size of changes in the state of the
repository and its temporal sequence.  Our
intention is to prove that, although with entirely different
characteristics, teams, rules and sizes, most repositories
independently of the number of collaborators and their real 
nature, self-organize, which implies that it is the nature of these
interactions, and not the object of the interaction, which takes the
project to a critical state. This critical state has already been
established 
% Antonio - in previous works?
% in a number of repositories, lo dice luego.
in a number of repositories with different types of
projects, including software or even literary works; in this paper we
apply a new methodology to measure changes and their sequence; we will
also focus
% Antonio - focusing?
on a wider range of repository sizes and ages, not only big and {\em
  old ones}, with two main objectives: establish their 
self-organized criticality state   % sorry, but, does "self-organized criticality" corresponds to SOC used bellow? In that case, lets define it here
or at least some features of it, and eventually try 
% Antonio - trying?
and find if {\em age} as measured as the number of changes 
% Antonio - changes o commits? Lo primero serÌan a nivel de car·cter, por ejemplo en lugar de un conjunto de cambios agrupado
is the only condition needed to find self-organization. 
% Antonio - comentar algo de los resultados obtenidos
Taking into account these measures in the repositories we can conclude that the number of % By measuring these? - Mario  
changes is the main, if not only, factor that creates a critical state
in software repositories.
% AÒadido - JJ
\end{abstract}

% A category with the (minimum) three required fields
%\category{H.4}{Information Systems Applications}{Miscellaneous}
%A category including the fourth, optional field follows...
\category{D.2.11}{Software Engineering}{Software Architectures}[Data abstraction]
\category{D.2.12}{Software Engineering}{Interoperability}[Distributed objects]
\category{I.2.8}{Artificial Intelligence}{Problem Solving, Control Methods, and Search}[Heuristic methods]

%sures, performance measures
\terms{Algorithms}

\keywords{Complex systems, self-organizing systems, self-organized
  criticality, power laws, artificial life}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   INTRODUCTION   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}\label{introduction}

The goal of automatic code improvement has been lately approached
successfully from a number of different angles
\cite{petke2014using,langdon2014genetic}. While noteworthy, these
methods do not deal with the true nature of software development,
which is done in a team and using a series of methodological as well
as social cues to get to release or to production. This essentially
means that any change by anyone will interact with other changes, not
only directly through tests, but also indirectly through knowledge
inserted or simply removal or addition of lines close to what other
programmer has done; this also implies that what can be optimal in a
first order approximation might not be in the frame of the
project. The projects have to be observed as a whole, and any approach
to genetic improvement must eventually deal with this complexity. But
in order to make improvement of software projects possible, we have to
find out a precise way of evaluating the state they are in, so that we
can compare the state of the project before and after the change. And
this is a challenge bigger than simply counting eliminated bugs or
tests passed. 

In this paper, we take the first steps towards the evaluation and
eventual improvement of software projects by treating them as complex
social systems. Several researchers have proved that many of them,
mainly large, long-running projects, of a self-organized critical
state \cite{bak1988self} in  
software repositories has been well established
\cite{wu2007empirical,gorshenev2004punctuated,Merelo2016:repominingANON,gao2014analysis} and  
attributed to a stigmergy process \cite{robles05} in which collaborators interact through the code
itself and through messages in other communication media, such as Slack or an IRC chat
application, task assignment systems or mailing lists. This is
probably just some of the self-organization processes taking place,
but the fact is that the model predicts that the system will reach a
critical state through self-organization given very few initial
conditions. 
In this
critical state there are specific dynamic behaviors, like small
changes in the code base provoking {\em avalanches} of changes of all sizes and long-distance
correlations that make a particular change in a file cause
further changes down the line in a regular pattern. 

% Antonio - lo que viene a continuaciÛn yo lo pondrÌa al inicio de la secciÛn, para introducir el concepto de 'critical state', que se referencia justo al principio de la introducciÛn ahora.
% Cambiado m·s arriba. Ahora habr· que re-revisar - JJ
The dynamics of self-organized criticality is sometimes compared to
that of a sand pile \cite{paczuski1996avalanche}, in the sense that
the actual shape tends 
to reach a {\em critical} state, represented in the sand pile by a
critical slope, and a single grain of sand creates avalanches
unrelated to the frequency of grains falling. This pile of sand is
also a simple model of a self-organized system that captures many of
its main characteristics, but its behavior is connected to the
experience of software developers and other people using work
coordination mechanisms to produce something measurable, that experience
certain periods of stasis followed by {\em avalanches} of work, new
code or new paragraphs without an apparent origin. 



The anecdotal
evidence gathered by the authors confirms this kind of events
happen in software development teams, mainly in open source. 
% Antonio - no sÈ la validez que tendr· esta evidencia...
% SÛlo para confirmar que no sÛlo sucede en grandes proyectos. El
% paper est· para probarlo - JJ
In open source projects there is usually a {\em core} team which has the
privilege to write directly to the repository. Code advances through
several mechanisms, but mainly by following a {\em roadmap} where
developers agree on a series of new features, and also bug fixes where
developers fix errors arising in production or pointed out by
users. Besides, many software projects have a series of participation 
guidelines indicating where and how users can spontaneously contribute
to the code. These contributions are incorporated, for instance, through 
the so-called {\em pull requests} in {\em git}, which means that the 
contributor {\em requests} the core team to {\em pull} or incorporate 
changes from her own repository.

Most software development nowadays is done using the git tool
\cite{loeliger2012version}. Git is a distributed source control
management tool based in a synchronize from
upstream-change-synchronize to upstream cycle. Developers {\em pull}
from upstream to bring their repository (or {\em repo}) up to date,
make changes and then {\em push} those changes to the upstream
repository. There is no {\em master} or {\em central} repository, but
usually there is one that is distinguished, which is the one deployed
to production or released. Development might happen in {\em branches}
which eventually get merged with the master branch in the central repository. 
% Antonio - se acaba de decir que no hay 'master', aunque ya sÈ que se llama asÌ la rama principal, queda un poco incongruente. Yo quitarÌa el master arriba, dejando sÛlo 'central'
% Corregido
Best practices usually dictate that changes, made through and
represented by {\em commits}, should be atomic, i. e., affect a single
function or file and be independently testable, with the object that
if something goes wrong the guilty commit can be 
immediately found and, if needed, reverted or fixed. That means that
commits necessarily have a small size; however, in some merging
processes, a method called {\em squash} is used, by which several
commits are merged into a single, bigger, one, possibly with the same
object. That means that commits, in some cases, might span many more
lines than what would be expected by single, atomic commits. At any
rate, commits record changes by the number of lines added or {\em
  eliminated}, making commit size, by which we mean the number of
lines affected by a commit, much more precise than the change of size
in the whole repository used by other studies, simply because it
measures real changes made usually by individual users, not aggregated
changes through all the repository as has been reported by other researchers.
% Antonio - cita...
% M·s bien explicaciÛn - JJ

Furthermore, the case for this
critical state is supported by several macro measures that certify the non-existence of a particular
scale in the size of changes
\cite{wu2007empirical,gorshenev2004punctuated,Merelo2016:repominingANON}, but in some cases they
also exhibit long-range 
correlations and a \emph{pink noise} \cite{szendro2001pink} in the power spectral density, with
\emph{noise} or variations with respect to the \emph{normal} frequency
changing in a way that is inversely proportional to it, higher frequency
changes getting a smaller spectral density \cite{Merelo2016:repominingANON}. 

The state in which the project is has obviously an influence in its
productivity, with some authors finding this state favors the
evolvability of the underlying software system \cite{1544757}, 
% Antonio - evolvability puede ser a mejor o a peor => improvement/enhancing
% Evolvability es bueno, porque lo hace m·s flexible a cambios - JJ
as opposed from the lack of this quality in software created by a
top-down organization process, considered more {\em brittle} in the
sense that a single needed change might break down the whole system. That is why this quality has been
mainly studied in free software systems which follow a more
open model of development; however, it might happen that, in the same
way it happens in neural systems \cite{10.3389/fnsys.2014.00166}, the
self-organized state might be essential to the software development
process, as long as it is done through an application that allows
collaboration, for instance, as a repository managed by a source
control system such as git. In fact, some explanations have been offered via
conservation laws \cite{6784340} and other usual complex network
mechanisms such as preferential attachment \cite{lin2015power}.
%% It reminds me about the cathedral vs bazaar discussion 
%% Add something about it if you want - JJ
At any rate, software projects can be considered complex systems and
as such we will study them in this paper. 

After some initial exploration of the subject and developing the
tools needed to mine repositories in GitHub \cite{merelo16:selfANON}, in
this paper we will study many different software repositories, all of
them in active development,  trying to find out whether the telltale
signs of self-organized criticality, as enumerated above. 

Previously we have applied these techniques to examining the software repository for the Moose Perl library
\cite{Merelo2016:repominingANON}, books written mainly by a single
person \cite{merelo16:slashANON} and papers written collaboratively \cite{merelo16:selfANON}. In this paper we are going  % maybe a reference or footnote to this repo (https://github.com/moose) should be added?  - Pedro
%Added citation to the paper
to work on a total of 16 papers, chosen to represent different
languages and in such a way that all of them have at least a few
thousand commits, independently of the actual time it has taken to
make them. Since repositories hold many kind of different files,
including art, documentation and building tools, We have worked mainly
on the code parts, and also focused on the code written in the two or
three main languages of the repository itself. We have focused on this
ones since in fact the dynamics of documentation of build tools is
probably completely different. Besides, we avoid generated artifacts
such as configuration files that might change completely during a
commit; in a word, we are working only with code, and only the kind of
code that is written by a human coder. 

After presenting a brief \protect\hyperlink{soa}{state of the art} next, 
followed by the \protect\hyperlink{methodology}{methodology},
obtained \protect\hyperlink{res}{results} will be presented % in the next section, 
and eventually we will expose our \protect\hyperlink{conc}{conclusions}. 

\hypertarget{soa}{\section{State of the art}\label{soa}}

As far as we know, there has not been a continuing line of research on
self-organized criticality in software projects or, for that matter,
any other kind of collaborative work teams. The main reason might be
that researchers have thoroughly
proved that software repositories seem to be in a SOC state,
\cite{wu2007empirical,gorshenev2004punctuated}, including our own
reports \cite{Merelo2016:repominingANON,merelo16:slashANON,merelo16:selfANON}
where we examine and establish the existence of repositories in a
critical state to which they have arrived via self-organization; the
fact that these repositories have different characteristics in terms
of the number of users, age and type of information they hold implies that
self-organization, as should be expected, is achieved with relative
ease. In fact, this state of self-organized criticality
quantitatively proves what has been already established via
qualitative analysis, the fact that in many successful software
projects, developers self-organize \cite{Crowston2007564}, which is
the preferred way of working in distributed and volunteer
teams \cite{crowston2012free}. In fact, this way of organization
matches our own experience in development of open source projects such
as \cite{ae09,2016arXiv160101607M}, which are developed mainly by one
or a few coders, helped sporadically by other coders that find an
error or adapt the code to particular situations. 
In fact, this self-organization has also been observed in similar
projects such as Wikipedia.

This self-organization, eventually, might produce a critical state
given the necessary conditions. However, there has been no work going further and
proving this even in the case that work is done by a few persons and
on repositories that are not devoted to software development. And this
critical state is key to carry the system to adaptive success, as
defined in \cite{benbya2006toward}. This paper presents the seven
mechanisms that create complexity in systems as initially enounced for
biological systems and apply them to information system
development. The principle of {\em change rate}, which appears in the
way of observation-orientation-decision-action, are very explicit in
open source development, where you usually observe a repository or
project for a certain time, they find if there is something to fix or
the way you can adapt it to your particular circumstances, decide what
to do and how to do it and eventually act on your fork, resulting in a
pull request to the original repository. These activities can
effectively be defined as social, so that teamwork in software
repositories is embedded in a social network. \cite{valverde2007self}
has proved how this network grows under the tension of top-down or
hierarchical rules and self-organization emerging from the bottom. At
any rate, quite clearly these software repositories are the record of
the activity of a complex network.

In this paper we will examine different repositories with the purpose
of finding out how that complex network effectively emerges. Next we
will present the methodology used to choose and mine information in
those repositories. 


\hypertarget{methodology}{\section{Methodology}\label{methodology}}
\label{sec:method}

We have chosen 16 repositores in different states of development, and representing from web frameworks such as Django to Atom plugins in the case of {\em language-perl6e}. They represent many different languages, either interpreted or compiled, and vary also in {\em profesionality}, from the aforementioned plugin to Docker, created and maintained by a professional community. 

In this paper we will work with the size of changes to a particular
set of files in the repository, selected via wildcards. We exclude other 
artifacts such as images or style files. To extract information
about changes to these files in the repositories, we analyze the
repository log  using a Perl script to extract the size of the changes that have been made to the considered files. 

Since changes include both the insertion and deletion of lines in committed files, the largest of these values is taken; in particular, this means that the addition of all changes will not be equal to the sum of
the sizes of all files. A change in two lines will appear in a diff as
``2 insertions, 2 deletions'', adding up to 0; that is why we consider
the larger of these two values; the main reason for doing so is also
that in fact, the algorithm that computes changes in the repository
examines similitude in lines and counts changes in two lines as two
insertions and two deletions. There is no way to find out whether
there have been actually two lines added somewhere and two deleted
somewhere else, so in absence of that, we opt for the heuristic of
using the largest of these two values as change size. This analysis
method is more precise that the one used by other authors, which takes
into account only changes in size in the whole repository, and does
not include activities such as refactoring that consist mainly in
making changes in place. It also has the granularity of single commits
and not days or weeks, which are not as problem-specific as using the
number of commits.

The Perl script generates a {\tt .csv} file with a single column with the
sequence of changes in size in the files of interest in each
repository. These data files, as well as the repositories where they have
been measured, are available with a free license in the repository
that also hosts this paper (hidden now for double blind review). 
% maybe we should add here the URL to the paper repo, as a footnote  - Pedro
% Done

The $x$ axes for these timelines does not correspond to physical time,
but simply to the sequence, and then only in changes of the
interesting files. In this sense, there is an important difference between
our research methodology, which considers discrete changes, to papers such
as  \cite{herraiz2009statistical}, which take into account {\em daily}
changes. We think that examining discrete changes does not impose a
particular rhythm, namely, daily, on the changes, but lets the
repository expose its own rhythm; it also allows us to examine
slow-changing repositories such as what is usual in non-critic open
source projects, that can be static for
a long time to experience a burst of changes all of a sudden;
precisely these changes can indicate an {\em avalanche} that is a
symptom of the underlying self-organized criticality state and might
be better detected using commits. An {\em avalanche} caused by a small change happening in a day followed by a flurry of changes fill appear as a big change if time units bigger than the discrete commit. 

Once the information from the repositories has been extracted, we
proceed to analyze it in the next section. 

\hypertarget{res}{\section{Results}\label{res}}

A summary of the statistical characteristics of the size of the commits,
in number of lines, is shown in Table \ref{t:stat}.
%
\begin{table*}
    \centering
<<commits, cache=FALSE,echo=FALSE>>=
kable( summary,"latex" )
@
\vspace*{1mm}
\caption{Summary of statistical measures for the software repositories we have
  been analyzing here. {\tt age} is measured in total number of
  commits that affect the files analyzed. The complete name is shown here,
  which includes the depth of the directory structure in a number and
  the extension. For instance, the first one has directories up to 4
  deep and uses CoffeScript ({\tt coffee}) and Perl 6 {\em p6}. They are all open source and can be found in the GitHub repository with the same name.\label{t:stat}}
\end{table*}
%
This table shows that, at least from a macro point of view, median and
averages are remarkably similar among themselves and with other repositories that have been examined. Median changes are never bigger than 100 lines and it can be as small as 6 or 9 lines. Averages span a bigger range, from around 22 lines to several tens of thousands in the case of Tensorflow. The fact that the average is so
separated from the median is already a hint that this is a skewed
distribution. The book analyzed in \cite{merelo16:slashANON} had a median
of 10 lines, but a mean of 150 lines changed, in a distribution that
is different, much more skewed towards larger sizes, while the
software library analyzed in \cite{Merelo2016:repominingANON} had a median
of 9 and a mean of close to 32, which is remarkably similar to one of
the papers analyzed here. This implies that the concept of {\em
  session}, or size of changes committed together, might be very
similar no matter what is the thing that is actually written. However, some repositories, specially ejabberd (a server written in Erlang for the Jabber protocol), Django and Tensorflow show the practice called {\em squashing}, which compresses several commits into a single one creating changes of several thousands lines. Those changes are not {\em organic} in the sense that they do not reflect the work of a single person. In the big picture of the self-organization of the repository, its impact will have to be assessed, but in principle it would not have to have an influence on the overall state, since their scale will also follow the same principles. 

The timeline of the commit sizes is represented in a line chart in Figure \ref{fig:smoothie} with logarithmic or
decimal \emph{y} scale and smoothing over several commits, either 10
or 20, depending on the color. The \emph{x} axis is simply the temporal
sequence of commits, while the \emph{y} axis is the absolute size of the
commit in number of lines. The serrated characteristic is the same, as well
as the big changes in scale, with some periods where small changes
happen and other that alternate big with small changes. A certain
\emph{rhythm} can be observed, which hints at large-scale
correlations, that is influence of changes happening now over changes
that occur several, or many, steps afterwards, in the future. 

% in this figure, the different subplots should be identified (maybe including the name of repo in each case)  - Pedro
%\includegraphics{analyzing-paper_files/figure-latex/smoothie-1.pdf}
\begin{figure*}[h!tb]
  \centering
<<smoothie,message=FALSE,echo=FALSE,warning=FALSE,fig.height=7,fig.subcap=summary$Name,out.width='.115\\linewidth'>>=
for (i in 1:length(lines) ) {
    lines[[i]]$x = as.numeric(row.names(lines[[i]]))
    print(ggplot(lines[[i]]) +geom_line(aes(x=x,y=SMA10,color='SMA10'))+geom_line(aes(x=x,y=SMA20,color='SMA20'))+scale_y_log10())
}
@ 
\caption{Timeline of changes for the four papers, with lines smoothed over 20 and 10 changes, shown in different colors.\label{fig:smoothie}}
\end{figure*}

Besides, these changes in scale might mean that commit sizes are distributed along a Pareto
distribution. We will examine this next, representing the number of changes of a particular
size in a log-log scale, with linear smoothing to show the trend in
Figure \ref{fig:changes}. 

% in this figure, the different subplots should be identified (maybe including the name of repo in each case)  - Pedro
%\includegraphics{analyzing-paper_files/figure-latex/linecount-1.pdf}
\begin{figure*}[h!tb]
  \centering
<<linecount,message=FALSE, fig.subcap=summary$Name, echo=FALSE,warning=FALSE,fig.height=4,out.width='.245\\linewidth'>>=
sizes.fit.df <- data.frame(Name = character(),
                           Coefficient = double(),
                           Intercept = double())
for (i in 1:length(lines) ) {
    by.lines <- group_by(lines[[i]],Lines.changed)
    lines.count <- summarize(by.lines, count=n())
    sizes.fit <- lm(log(1+lines.count$Lines.changed) ~ log(lines.count$count))
    repo <- strsplit(paste(summary[[1]][i],""),"_",fixed=T)
    sizes.fit.df <- rbind( sizes.fit.df,
                          data.frame( Name = repo[[1]][1],
                                     Intercept = summary(sizes.fit)$coefficients[1],
                                     Coefficient = summary(sizes.fit)$coefficients[2] ))
    print(ggplot(lines.count, aes(x=Lines.changed, y=count))+geom_point()+scale_x_log10()+scale_y_log10()+stat_smooth())
}
@ 
\caption{Number of changes vs size in a log-log scale.\label{fig:changes}}
\end{figure*}
%
This chart shows what seems to be a Zipf distribution, with the commit sizes
ranked in descending order and plotted with a logarithmic \emph{y}
axis. This distribution shows, in all cases, a {\em tail}
corresponding to big changes. This might be simply a consequence of
different practices by different authors, with some preferring atomic
changes to single lines or paragraphs and others writing down whole
sections; in some cases, it corresponds also to reuse of common parts
of papers (authors, acknowledgements, description of a method) to
create the initial versions of the paper; finally, in some cases
comments are deleted before the final version is submitted, so these
{\em tails} are not really unexpected. If you follow the charts also
in the direction of increasing number of commits it can be seen how
the linearity of the distribution becomes more crisp; in the first two
papers there are simply not enough number of commits to actually show
this Pareto distribution, but in the last case there is a very clear
log-log distribution. 

These distributions can, in fact, be linearly fit to a log-log distribution with coefficients
shown in Table \ref{t:sizes}. 
%
\begin{table}
    \centering
<<sizes, cache=FALSE,echo=FALSE>>=
kable( sizes.fit.df,"latex" )
@
\vspace*{2mm}
\caption{Summary of coefficients of the linear models adjusting the
  number of lines and size.\label{t:sizes}}
\end{table}
%
These values are also similar to those found in
\cite{Merelo2016:repominingANON}, where the intercept was 6.02, above the
table, and the slope -0.001, a very mild slope that hints at a big
number of changes and might in fact indicate that, as would be
expected, the intercept increases and the slope decreases with the
number of changes. The shape of the line in
\cite{Merelo2016:repominingANON} in fact might be more similar to a {\em
  broken stick}; this is a matter that deserves further
investigation. In the case of \cite{merelo16:slashANON} values are
somewhere in the middle, 5.7 and -0.96. The slope is quite similar
indeed, and the intercept might point to the fact that size changes
are larger when fiction is being written, which also matches the macro
averages and medians observed above. 

The scale free nature of the work in the repository can be more
properly observed by looking at the changes in some other way, ranking them by size
and representing them in a chart with a logarithmic \(y\) axis, as well as
in the form of an histogram. This is done in Figure \ref{fig:zipf}. 

% in this figure, the different subplots should be identified (maybe including the name of repo in each case)  - Pedro
\begin{figure*}[h!tb]
  \centering
<<powerlaw,message=FALSE, fig.subcap=summary$Name,echo=FALSE,warning=FALSE,fig.height=4,out.width='.245\\linewidth'>>=
zipf.fit.df <- data.frame(Name = character(),
                          Coefficient = double(),
                          Intercept = double())
for (i in 1:length(lines) ) {
    sorted.lines <- data.frame(x=1:length(lines[[i]]$Lines.changed),Lines.changed=as.numeric(lines[[i]][order(-lines[[i]]$Lines.changed),]$Lines.changed))
    print(ggplot()+geom_point(data=sorted.lines,aes(x=x,y=Lines.changed))+scale_y_log10())
    sorted.lines.no0 <- sorted.lines[sorted.lines$Lines.changed>0,]
    repo <- strsplit(paste(summary[[1]][i],""),"_")
    zipf.fit <- lm(log(sorted.lines.no0$Lines.changed) ~ sorted.lines.no0$x)
    zipf.fit.df <- rbind( zipf.fit.df,
                         data.frame( Name = repo[[1]][1],
                                    Intercept = summary(zipf.fit)$coefficients[1],
                                    Coefficient = summary(zipf.fit)$coefficients[2] ))
}
@ 
\caption{Changes, ordered by size, and represented in a logarithmic
  $y$ axis. Side by side, the histogram and Zipf chart for the four papers analyzed.\label{fig:zipf}}
\end{figure*}
%
%
The Zipf exponents and intercepts for these models are shown in Table \ref{t:zipf},
and are of the same order, but different range, of the one found  in
\cite{merelo16:slashANON}, where it hovers around 6 for the intercept and
-0.01 for the slope.
%
\begin{table}
    \centering
<<zipf, cache=FALSE,echo=FALSE>>=
kable( zipf.fit.df,"latex" )
@
\vspace*{2mm}
\caption{Summary of Zipf coefficients of the linear models adjusting the
  number of lines and size.\label{t:zipf}}
\end{table}
%
The {\em evolution} in the nature of the distribution can be observed,
from a more or less straight line in the first cases, to something
more similar to a broken stick model in the last one, although it can
still be linearly fit to a log scale and there is a regime of size
changes that is still logarithmic in scale. Whatever the actual
distribution, there is no doubt that changes do not organize
themselves along a central value and that there is scale-free nature
in them, which is, besides, independent of the {\em age} or total
number of changes of the paper, as has been shown above. 

Finally, these scale distributions hints at the possibility of
long-scale correlations, but in order to find this out, we will have
to plot the partial autocorrelation of the sequence, that is, the
relationship between the size of a change and the rest of the changes
in the sequence. This is computed and plotted in Figure
\ref{fig:auto}. 
%
% in this figure, the different subplots should be identified (maybe including the name of repo in each case)  - Pedro
%\includegraphics{analyzing-paper_files/figure-latex/autocorrelation-1.pdf}
\begin{figure*}[h!tb]
  \centering
<<autocorrelation,message=FALSE, cache=FALSE,echo=FALSE,fig.height=4,fig.subcap=summary$Name,out.width='.115\\linewidth'>>=
for (i in 1:length(lines) ) {
    print(autoplot(pacf(lines[[i]]$Lines.changed, plot=FALSE) ))
}
@ 
\caption{Autocorrelation plot. The order of the papers is the same as in the rest of the figures, increasing in age from the top left to bottom right. The horizontal lines show the level of statistical significant, with any line surpassing it indicating positive or negative self-correlation .\label{fig:auto}}
\end{figure*}
% 
Autocorrelation is significant only if the lines go over the average
plotted as a dashed line. The long distance correlations, already
found in \cite{Merelo2016:repominingANON}, are present here. In that case, there was positive
autocorrelation in the 21 commit period; in this case, it appears at 25
and 15. It shows, anyway, that the size of a commit has a clear
influence further down writing history, with high autocorrelations
around 20 commits. In these repositories of increasing age, we find
that actual long-distance autocorrelation only happens when they age,
with no long-distance significant autocorrelation in the first two
repositories, and a significant one in the two bottom repositories. In
both cases, correlation happens at the distance of 13-25 commits,
exactly as it happened before. However, autocorrelation seems to
disappear in the older repositories, at least for that long
distances. This might indicate significant differences for other types
of work, but it will need further research to find out, in a more
precise way, the ranges of distances where autocorrelation is
significant. 

Once two of the three features of self-organized criticality have been
proved, at least in some of the repositories, we will
focus on the third, the presence of \emph{pink} noise, as measured by
the power spectral density. This is shown in Figure \ref{fig:spectrum}, where the power spectral density is shown for the four papers. A {\em pink} noise would be characterized by a spectrum with a negative slope, with decreasing power the higher the frequency. 
%
% in this figure, the different subplots should be identified (maybe including the name of repo in each case)  - Pedro
%\includegraphics{analyzing-paper_files/figure-latex/spectrum-1.pdf}
\begin{figure*}[h!tb]
  \centering
<<spectrum,message=FALSE, cache=FALSE,echo=FALSE,fig.height=4,fig.subcap=summary$Name,out.width='.245\\linewidth'>>=  
spec.fit.df <- data.frame(Name = character(),
                          Coefficient = double(),
                          p = double())
for (i in 1:length(lines) ) {
    this.spectrum <- spectrum(lines[[i]]$Lines.changed, plot=FALSE)
    print(autoplot( this.spectrum ) + scale_x_log10() )
    spec.fit <- lm(log(this.spectrum$spec) ~ log(this.spectrum$freq))
    repo <- strsplit(paste(summary[[1]][i],""),"_")
    f <- summary(spec.fit)$fstatistic
    p <- pf(f[1],f[2],f[3],lower.tail=F)
    attributes(p) <- NULL
    spec.fit.df <- rbind( spec.fit.df,
                         data.frame( Name = repo[[1]][1],
                                    p = p,
                                    Coefficient = summary(spec.fit)$coefficients[2] ))
}
@ 
\caption{Spectral density of changes. The repos are in the same order as above.  \label{fig:spectrum}}
\end{figure*}
%
\begin{table}
    \centering
<<spec.tab, cache=FALSE,echo=FALSE>>=
kable( spec.fit.df,"latex" )
@
\vspace*{2mm}
\caption{Summary of coefficients of the linear models adjusting the
  power spectrum with the p-value of the fit. Pink noise would
  correspond to a coefficient of -1, although in the cases that
  p-value > 0.05 the fit does not hold. \label{t:spec}}
\end{table}

In this case, we see that this {\em trend} appears with increasing
clarity from top left to bottom right. The actual coefficients are
shown in Table \ref{t:spec}. Pink noise is characterized by
coefficient values between 0 and 2, and that is the case for all of
the repositories studied, with the only difference being the goodness
of the fit, which makes the hypothesis hold in all but 3 repositories:
{\tt language-perl6fe}, {\tt cask} and {\tt tty}. In all cases they
are repositories with less than 1000 changes, although other
repositories with similar number of commits do show this {\em pink
  noise} feature. 

Once the three main features of systems in self-organized state have
been measured for the papers under study, we will present in the next
Section our conclusions. 


\hypertarget{conc}{\section{Conclusions}\label{conc}}

In this paper we were interesting in finding traces of self-organized criticality in the repositories of scientific papers by looking for certain features that are peculiar to the critical state: scale-free behavior, long-distance correlations and pink we. 

The methodology that we have used counts size of commits as a discrete measure, not \emph{dailies} or other time
measure, since development often stops for several days more clearly in
the case of this paper, where nothing was done for months, and nothing   % "this paper" refers to the "literaturame" paper (self-reference), or is something that remains from a previous text?
between submission and the first revision. We think that commits, and
not actual time measures, will show a much clearer picture of the state
of the repository, since they correspond to units of work done and are
also related to discrete tasks in the ticketing system.
% Comment: There is other information that could be exploited that
% IMO is more related with self-organization, and is the author of
% the commit. Maybe rules of interaction arise when for instance some one takes the lead
% and others wait for him to work, and then make little corrections.
% This could be the content of other papers, not this one...

After analyzing the software repositories that hold the papers, we can conclude that, in fact, all repositories analyzed show some of the features, specially freedom of a particular scale in the size of the changes; however, we could conclude from the measures taken above that there is a certain amount of interaction needed before the critical state settles. From the limited amount of repositories we have studied, we could put this number at around 100 changes, but of course there is further studies to be made in this subject. In particular, this would indicate that the only condition needed for the critical state to arise is the age of the repository, or maybe its size. Since the four papers were developed by different number and authors, the presence of absence of other artifacts might also play a role. However, we do not think that is the case. 

In line with our open science policy, you can draw your own conclusions on your own repos by running the Perl
script hosted in http://anonymousu.rl 
%\url{http://github.com/JJ/literaturame}
. This
repository holds also the data used in this study, as well as the
source of this paper. 

As future line of work, we will first try to gather data from more repositories, specially in the boundary where we think self-organization arises, around 100 commits, and these with other
type of repositories, and see if there are some outstanding and
statistically significant differences, which would be attributed rather
than the substrate itself, to different types of collaboration. We would also like to make more precise models of the ranked change sizes, as well as the relation between number of changes and its size. A study of particular circumstances of every repository will also help us to understand what self-organization means and, finally, as was our initial objective, if this fact can be used to create methodologies that improve productivity in work teams. 


\section*{Acknowledgements}
%This work has been supported in part by: de Ministerio espa\~{n}ol de Econom\'{\i}a y Competitividad under project TIN2014-56494-C4-3-P (UGR-EPHEMECH).
Several projects \\
taking this much space \\

\bibliographystyle{plain}
%\bibliographystyle{splncs03}
\bibliography{geneura,biblio,anon}

\end{document}
